{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24bb9844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179  images to be resized.\n",
      "179  images resized.\n",
      "182  images to be resized.\n",
      "182  images resized.\n",
      "141  images to be resized.\n",
      "141  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 502 입니다.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (502, 224, 224, 3)\n",
      "y_train shape: (502,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(224,224)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\n",
    "\n",
    "# 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "image_dir_path2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "image_dir_path3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path1)\n",
    "resize_images(image_dir_path2)\n",
    "resize_images(image_dir_path3)\n",
    "image_dir_path_test1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "image_dir_path_test2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "image_dir_path_test3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path_test1)\n",
    "resize_images(image_dir_path_test2)\n",
    "resize_images(image_dir_path_test3)\n",
    "\n",
    "def load_data(img_path, number_of_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=224\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path, 502)\n",
    "image_dir_path_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path_test, 300)\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c575e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (502, 224, 224, 3)\n",
      "Before Reshape - x_test_norm shape: (300, 224, 224, 3)\n",
      "After Reshape - x_train_reshaped shape: (502, 224, 224, 3)\n",
      "After Reshape - x_test_reshaped shape: (300, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224,224,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 224, 224, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 224, 224, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382ef4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - 4s 55ms/step - loss: 1.5256 - accuracy: 0.3446\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.1272 - accuracy: 0.3665\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.1314 - accuracy: 0.3327\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0998 - accuracy: 0.3566\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0827 - accuracy: 0.4502\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0367 - accuracy: 0.4502\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.9036 - accuracy: 0.5359\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.8567 - accuracy: 0.5498\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.6936 - accuracy: 0.6295\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.7262 - accuracy: 0.5916\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6195 - accuracy: 0.7012\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5522 - accuracy: 0.7510\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5205 - accuracy: 0.7769\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4281 - accuracy: 0.8406\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4124 - accuracy: 0.8327\n",
      "10/10 - 0s - loss: 0.7913 - accuracy: 0.8433\n",
      "test_loss: 0.7912881374359131 \n",
      "test_accuracy: 0.8433333039283752\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=15)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172ab7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
